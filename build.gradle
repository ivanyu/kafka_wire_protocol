// Licensed to the Apache Software Foundation (ASF) under one or more
// contributor license agreements.  See the NOTICE file distributed with
// this work for additional information regarding copyright ownership.
// The ASF licenses this file to You under the Apache License, Version 2.0
// (the "License"); you may not use this file except in compliance with
// the License.  You may obtain a copy of the License at
//
//    http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

import org.ajoberstar.grgit.Grgit
import org.gradle.api.JavaVersion

import java.nio.charset.StandardCharsets

buildscript {
  repositories {
    mavenCentral()
  }
  apply from: "$rootDir/gradle/dependencies.gradle"

  dependencies {
    // For Apache Rat plugin to ignore non-Git files
    classpath "org.ajoberstar.grgit:grgit-core:$versions.grgit"
  }
}

plugins {
  id 'com.github.ben-manes.versions' version '0.48.0'
  id 'idea'
  id 'jacoco'
  id 'java-library'
  id 'org.owasp.dependencycheck' version '8.2.1'
  id 'org.nosphere.apache.rat' version "0.8.1"
  id "io.swagger.core.v3.swagger-gradle-plugin" version "${swaggerVersion}"

  // When updating the spotbugs gradle plugin, check if it already
  // includes spotbugs version 4.7.4, in which case CVE-2022-42920 can
  // be dropped from gradle/resources/dependencycheck-suppressions.xml
  id "com.github.spotbugs" version '5.1.3' apply false
  id 'org.scoverage' version '8.0.3' apply false
  // Updating the shadow plugin version to 8.1.1 causes issue with signing and publishing the shadowed
  // artifacts - see https://github.com/johnrengelman/shadow/issues/901
  id 'com.github.johnrengelman.shadow' version '8.1.0' apply false
  id 'com.diffplug.spotless' version '6.14.0' apply false // 6.14.1 and newer require Java 11 at compile time, so we can't upgrade until AK 4.0
}

ext {
  gradleVersion = versions.gradle
  minJavaVersion = 8
  buildVersionFileName = "kafka-version.properties"

  defaultMaxHeapSize = "2g"
  defaultJvmArgs = ["-Xss4m", "-XX:+UseParallelGC"]

  // "JEP 403: Strongly Encapsulate JDK Internals" causes some tests to fail when they try
  // to access internals (often via mocking libraries). We use `--add-opens` as a workaround
  // for now and we'll fix it properly (where possible) via KAFKA-13275.
  if (JavaVersion.current().isCompatibleWith(JavaVersion.VERSION_16))
    defaultJvmArgs.addAll(
      "--add-opens=java.base/java.io=ALL-UNNAMED",
      "--add-opens=java.base/java.lang=ALL-UNNAMED",
      "--add-opens=java.base/java.nio=ALL-UNNAMED",
      "--add-opens=java.base/java.nio.file=ALL-UNNAMED",
      "--add-opens=java.base/java.util=ALL-UNNAMED",
      "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED",
      "--add-opens=java.base/java.util.regex=ALL-UNNAMED",
      "--add-opens=java.base/java.util.stream=ALL-UNNAMED",
      "--add-opens=java.base/java.text=ALL-UNNAMED",
      "--add-opens=java.base/java.time=ALL-UNNAMED",
      "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED"
    )

  maxTestForks = project.hasProperty('maxParallelForks') ? maxParallelForks.toInteger() : Runtime.runtime.availableProcessors()
  maxScalacThreads = project.hasProperty('maxScalacThreads') ? maxScalacThreads.toInteger() :
      Math.min(Runtime.runtime.availableProcessors(), 8)
  userIgnoreFailures = project.hasProperty('ignoreFailures') ? ignoreFailures : false

  userMaxTestRetries = project.hasProperty('maxTestRetries') ? maxTestRetries.toInteger() : 0
  userMaxTestRetryFailures = project.hasProperty('maxTestRetryFailures') ? maxTestRetryFailures.toInteger() : 0

  skipSigning = project.hasProperty('skipSigning') && skipSigning.toBoolean()
  shouldSign = !skipSigning && !version.endsWith("SNAPSHOT")

  mavenUrl = project.hasProperty('mavenUrl') ? project.mavenUrl : ''
  mavenUsername = project.hasProperty('mavenUsername') ? project.mavenUsername : ''
  mavenPassword = project.hasProperty('mavenPassword') ? project.mavenPassword : ''

  userShowStandardStreams = project.hasProperty("showStandardStreams") ? showStandardStreams : null

  userTestLoggingEvents = project.hasProperty("testLoggingEvents") ? Arrays.asList(testLoggingEvents.split(",")) : null

  userEnableTestCoverage = project.hasProperty("enableTestCoverage") ? enableTestCoverage : false

  userKeepAliveModeString = project.hasProperty("keepAliveMode") ? keepAliveMode : "daemon"
  userKeepAliveMode = KeepAliveMode.values().find(m -> m.name().toLowerCase().equals(userKeepAliveModeString))
  if (userKeepAliveMode == null) {
    def keepAliveValues = KeepAliveMode.values().collect(m -> m.name.toLowerCase())
    throw new GradleException("Unexpected value for keepAliveMode property. Expected one of $keepAliveValues, but received: $userKeepAliveModeString")
  }

  // See README.md for details on this option and the reasoning for the default
  userScalaOptimizerMode = project.hasProperty("scalaOptimizerMode") ? scalaOptimizerMode : "inline-kafka"
  def scalaOptimizerValues = ["none", "method", "inline-kafka", "inline-scala"]
  if (!scalaOptimizerValues.contains(userScalaOptimizerMode))
    throw new GradleException("Unexpected value for scalaOptimizerMode property. Expected one of $scalaOptimizerValues, but received: $userScalaOptimizerMode")

  generatedDocsDir = new File("${project.rootDir}/docs/generated")
  repo = file("$rootDir/.git").isDirectory() ? Grgit.open(currentDir: project.getRootDir()) : null

  commitId = determineCommitId()

  addParametersForTests = { name, options ->
    // -parameters generates arguments with parameter names in TestInfo#getDisplayName.
    // ref: https://github.com/junit-team/junit5/blob/4c0dddad1b96d4a20e92a2cd583954643ac56ac0/junit-jupiter-params/src/main/java/org/junit/jupiter/params/ParameterizedTest.java#L161-L164
    if (name == "compileTestJava" || name == "compileTestScala")
      options.compilerArgs << "-parameters"
  }
}

allprojects {

  repositories {
    mavenCentral()
  }

  dependencyUpdates {
    revision="release"
    resolutionStrategy {
      componentSelection { rules ->
        rules.all { ComponentSelection selection ->
          boolean rejected = ['snap', 'alpha', 'beta', 'rc', 'cr', 'm'].any { qualifier ->
            selection.candidate.version ==~ /(?i).*[.-]${qualifier}[.\d-]*/
          }
          if (rejected) {
            selection.reject('Release candidate')
          }
        }
      }
    }
  }

  configurations.all {
    // zinc is the Scala incremental compiler, it has a configuration for its own dependencies
    // that are unrelated to the project dependencies, we should not change them
    if (name != "zinc") {
      resolutionStrategy {
        force(
          // be explicit about the javassist dependency version instead of relying on the transitive version
          libs.javassist,
          // ensure we have a single version in the classpath despite transitive dependencies
          libs.scalaLibrary,
          libs.scalaReflect,
          libs.jacksonAnnotations,
          // be explicit about the Netty dependency version instead of relying on the version set by
          // ZooKeeper (potentially older and containing CVEs)
          libs.nettyHandler,
          libs.nettyTransportNativeEpoll,
	  // be explicit about the reload4j version instead of relying on the transitive versions
	  libs.log4j
        )
      }
    }
  }
  task printAllDependencies(type: DependencyReportTask) {}

  tasks.withType(Javadoc) {
    options.charSet = 'UTF-8'
    options.docEncoding = 'UTF-8'
    options.encoding = 'UTF-8'
    options.memberLevel = JavadocMemberLevel.PUBLIC  // Document only public members/API
    // Turn off doclint for now, see https://blog.joda.org/2014/02/turning-off-doclint-in-jdk-8-javadoc.html for rationale
    options.addStringOption('Xdoclint:none', '-quiet')

    // The URL structure was changed to include the locale after Java 8
    if (JavaVersion.current().isJava11Compatible())
      options.links "https://docs.oracle.com/en/java/javase/${JavaVersion.current().majorVersion}/docs/api/"
    else
      options.links "https://docs.oracle.com/javase/8/docs/api/"
  }
}

def determineCommitId() {
  def takeFromHash = 16
  if (project.hasProperty('commitId')) {
    commitId.take(takeFromHash)
  } else if (repo != null) {
    repo.head().id.take(takeFromHash)
  } else {
    "unknown"
  }
}

apply from: file('wrapper.gradle')

if (repo != null) {
  rat {
    dependsOn subprojects.collect {
      it.tasks.matching {
        it.name == "processMessages" || it.name == "processTestMessages"
      }
    }

    verbose.set(true)
    reportDir.set(project.file('build/rat'))
    stylesheet.set(file('gradle/resources/rat-output-to-html.xsl'))

    // Exclude everything under the directory that git should be ignoring via .gitignore or that isn't checked in. These
    // restrict us only to files that are checked in or are staged.
    excludes = new ArrayList<String>(repo.clean(ignore: false, directories: true, dryRun: true))
    // And some of the files that we have checked in should also be excluded from this check
    excludes.addAll([
        '**/.git/**',
        '**/build/**',
        'CONTRIBUTING.md',
        'PULL_REQUEST_TEMPLATE.md',
        'gradlew',
        'gradlew.bat',
        'gradle/wrapper/gradle-wrapper.properties',
        'trogdor/README.md',
        '**/README.md',
        '**/id_rsa',
        '**/id_rsa.pub',
        'checkstyle/suppressions.xml',
        'streams/quickstart/java/src/test/resources/projects/basic/goal.txt',
        'streams/streams-scala/logs/*',
        'licenses/*',
        '**/generated/**',
        'clients/src/test/resources/serializedData/*',
        'docker/test/fixtures/secrets/*',
        'docker/examples/fixtures/secrets/*',
        'docker/docker_official_images/.gitkeep'
    ])
  }
} else {
  rat.enabled = false
}
println("Starting build with version $version (commit id ${commitId == null ? "null" : commitId.take(8)}) using Gradle $gradleVersion, Java ${JavaVersion.current()} and Scala ${versions.scala}")
println("Build properties: maxParallelForks=$maxTestForks, maxScalacThreads=$maxScalacThreads, maxTestRetries=$userMaxTestRetries")

subprojects {

  // enable running :dependencies task recursively on all subprojects
  // eg: ./gradlew allDeps
  task allDeps(type: DependencyReportTask) {}
  // enable running :dependencyInsight task recursively on all subprojects
  // eg: ./gradlew allDepInsight --configuration runtime --dependency com.fasterxml.jackson.core:jackson-databind
  task allDepInsight(type: DependencyInsightReportTask) {showingAllVariants = false} doLast {}

  apply plugin: 'java-library'
  apply plugin: 'checkstyle'
  apply plugin: "com.github.spotbugs"

  // We use the shadow plugin for the jmh-benchmarks module and the `-all` jar can get pretty large, so
  // don't publish it
  def shouldPublish = !project.name.equals('jmh-benchmarks')
  def shouldPublishWithShadow = (['clients'].contains(project.name))

  if (shouldPublish) {
    apply plugin: 'maven-publish'
    apply plugin: 'signing'

    // Add aliases for the task names used by the maven plugin for backwards compatibility
    // The maven plugin was replaced by the maven-publish plugin in Gradle 7.0
    tasks.register('install').configure { dependsOn(publishToMavenLocal) }
    tasks.register('uploadArchives').configure { dependsOn(publish) }
  }

  // apply the eclipse plugin only to subprojects that hold code. 'connect' is just a folder.
  if (!project.name.equals('connect')) {
    apply plugin: 'eclipse'
    fineTuneEclipseClasspathFile(eclipse, project)
  }

  java {
    consistentResolution {
      // resolve the compileClasspath and then "inject" the result of resolution as strict constraints into the runtimeClasspath
      useCompileClasspathVersions()
    }
  }

  tasks.withType(JavaCompile) {
    options.encoding = 'UTF-8'
    options.compilerArgs << "-Xlint:all"
    // temporary exclusions until all the warnings are fixed
    if (!project.path.startsWith(":connect") && !project.path.startsWith(":storage"))
      options.compilerArgs << "-Xlint:-rawtypes"
    options.compilerArgs << "-Xlint:-serial"
    options.compilerArgs << "-Xlint:-try"
    options.compilerArgs << "-Werror"

    // --release is the recommended way to select the target release, but it's only supported in Java 9 so we also
    // set --source and --target via `sourceCompatibility` and `targetCompatibility` a couple of lines below
    if (JavaVersion.current().isJava9Compatible())
      options.release = minJavaVersion
    // --source/--target 8 is deprecated in Java 20, suppress warning until Java 8 support is dropped in Kafka 4.0
    if (JavaVersion.current().isCompatibleWith(JavaVersion.VERSION_20))
      options.compilerArgs << "-Xlint:-options"

    addParametersForTests(name, options)
  }

  java {
    // We should only set this if Java version is < 9 (--release is recommended for >= 9), but the Scala plugin for IntelliJ sets
    // `-target` incorrectly if this is unset
    sourceCompatibility = minJavaVersion
    targetCompatibility = minJavaVersion
  }

  if (shouldPublish) {

    publishing {
      repositories {
        // To test locally, invoke gradlew with `-PmavenUrl=file:///some/local/path`
        maven {
          url = mavenUrl
          credentials {
            username = mavenUsername
            password = mavenPassword
          }
        }
      }
      publications {
        mavenJava(MavenPublication) {
          if (!shouldPublishWithShadow) {
            from components.java
          } else {
            apply plugin: 'com.github.johnrengelman.shadow'
            project.shadow.component(mavenJava)

            // Fix for avoiding inclusion of runtime dependencies marked as 'shadow' in MANIFEST Class-Path.
            // https://github.com/johnrengelman/shadow/issues/324
            afterEvaluate {
              pom.withXml { xml ->
                if (xml.asNode().get('dependencies') == null) {
                  xml.asNode().appendNode('dependencies')
                }
                def dependenciesNode = xml.asNode().get('dependencies').get(0)
                project.configurations.shadowed.allDependencies.each {
                  def dependencyNode = dependenciesNode.appendNode('dependency')
                  dependencyNode.appendNode('groupId', it.group)
                  dependencyNode.appendNode('artifactId', it.name)
                  dependencyNode.appendNode('version', it.version)
                  dependencyNode.appendNode('scope', 'runtime')
                }
              }
            }
          }

          afterEvaluate {
            ["srcJar", "javadocJar", "scaladocJar", "testJar", "testSrcJar"].forEach { taskName ->
              def task = tasks.findByName(taskName)
              if (task != null)
                artifact task
            }

            artifactId = base.archivesName.get()
            pom {
              name = 'Apache Kafka'
              url = 'https://kafka.apache.org'
              licenses {
                license {
                  name = 'The Apache License, Version 2.0'
                  url = 'http://www.apache.org/licenses/LICENSE-2.0.txt'
                  distribution = 'repo'
                }
              }
            }
          }
        }
      }
    }

    if (shouldSign) {
      signing {
        sign publishing.publications.mavenJava
      }
    }
  }

  // Remove the relevant project name once it's converted to JUnit 5
  def shouldUseJUnit5 = !(["runtime"].contains(it.project.name))

  def testLoggingEvents = ["passed", "skipped", "failed"]
  def testShowStandardStreams = false
  def testExceptionFormat = 'full'
  // Gradle built-in logging only supports sending test output to stdout, which generates a lot
  // of noise, especially for passing tests. We really only want output for failed tests. This
  // hooks into the output and logs it (so we don't have to buffer it all in memory) and only
  // saves the output for failing tests. Directory and filenames are such that you can, e.g.,
  // create a Jenkins rule to collect failed test output.
  def logTestStdout = {
    def testId = { TestDescriptor descriptor ->
      "${descriptor.className}.${descriptor.name}".toString()
    }

    def logFiles = new HashMap<String, File>()
    def logStreams = new HashMap<String, FileOutputStream>()
    beforeTest { TestDescriptor td ->
      def tid = testId(td)
      // truncate the file name if it's too long
      def logFile = new File(
              "${projectDir}/build/reports/testOutput/${tid.substring(0, Math.min(tid.size(),240))}.test.stdout"
      )
      logFile.parentFile.mkdirs()
      logFiles.put(tid, logFile)
      logStreams.put(tid, new FileOutputStream(logFile))
    }
    onOutput { TestDescriptor td, TestOutputEvent toe ->
      def tid = testId(td)
      // Some output can happen outside the context of a specific test (e.g. at the class level)
      // and beforeTest/afterTest seems to not be invoked for these cases (and similarly, there's
      // a TestDescriptor hierarchy that includes the thread executing the test, Gradle tasks,
      // etc). We see some of these in practice and it seems like something buggy in the Gradle
      // test runner since we see it *before* any tests and it is frequently not related to any
      // code in the test (best guess is that it is tail output from last test). We won't have
      // an output file for these, so simply ignore them. If they become critical for debugging,
      // they can be seen with showStandardStreams.
      if (td.name == td.className || td.className == null) {
        // silently ignore output unrelated to specific test methods
        return
      } else if (logStreams.get(tid) == null) {
        println "WARNING: unexpectedly got output for a test [${tid}]" +
                " that we didn't previously see in the beforeTest hook." +
                " Message for debugging: [" + toe.message + "]."
        return
      }
      try {
        logStreams.get(tid).write(toe.message.getBytes(StandardCharsets.UTF_8))
      } catch (Exception e) {
        println "ERROR: Failed to write output for test ${tid}"
        e.printStackTrace()
      }
    }
    afterTest { TestDescriptor td, TestResult tr ->
      def tid = testId(td)
      try {
        logStreams.get(tid).close()
        if (tr.resultType != TestResult.ResultType.FAILURE) {
          logFiles.get(tid).delete()
        } else {
          def file = logFiles.get(tid)
          println "${tid} failed, log available in ${file}"
        }
      } catch (Exception e) {
        println "ERROR: Failed to close stdout file for ${tid}"
        e.printStackTrace()
      } finally {
        logFiles.remove(tid)
        logStreams.remove(tid)
      }
    }
  }

  // The suites are for running sets of tests in IDEs.
  // Gradle will run each test class, so we exclude the suites to avoid redundantly running the tests twice.
  def testsToExclude = ['**/*Suite.class']
  // Exclude PowerMock tests when running with Java 16 or newer until a version of PowerMock that supports the relevant versions is released
  // The relevant issues are https://github.com/powermock/powermock/issues/1094 and https://github.com/powermock/powermock/issues/1099
  if (JavaVersion.current().isCompatibleWith(JavaVersion.VERSION_16)) {
    testsToExclude.addAll([
      // connect tests
      "**/KafkaConfigBackingStoreTest.*"
    ])
  }

  test {
    maxParallelForks = maxTestForks
    ignoreFailures = userIgnoreFailures

    maxHeapSize = defaultMaxHeapSize
    jvmArgs = defaultJvmArgs

    testLogging {
      events = userTestLoggingEvents ?: testLoggingEvents
      showStandardStreams = userShowStandardStreams ?: testShowStandardStreams
      exceptionFormat = testExceptionFormat
      displayGranularity = 0
    }
    logTestStdout.rehydrate(delegate, owner, this)()

    exclude testsToExclude

    if (shouldUseJUnit5)
      useJUnitPlatform()

    retry {
      maxRetries = userMaxTestRetries
      maxFailures = userMaxTestRetryFailures
    }
  }

  task integrationTest(type: Test, dependsOn: compileJava) {
    maxParallelForks = maxTestForks
    ignoreFailures = userIgnoreFailures

    // Increase heap size for integration tests
    maxHeapSize = "2560m"
    jvmArgs = defaultJvmArgs


    testLogging {
      events = userTestLoggingEvents ?: testLoggingEvents
      showStandardStreams = userShowStandardStreams ?: testShowStandardStreams
      exceptionFormat = testExceptionFormat
      displayGranularity = 0
    }
    logTestStdout.rehydrate(delegate, owner, this)()

    exclude testsToExclude

    if (shouldUseJUnit5) {
      if (project.name == 'streams') {
        useJUnitPlatform {
          includeTags "integration"
          includeTags "org.apache.kafka.test.IntegrationTest"
	  // Both engines are needed to run JUnit 4 tests alongside JUnit 5 tests.
          // junit-vintage (JUnit 4) can be removed once the JUnit 4 migration is complete.
          includeEngines "junit-vintage", "junit-jupiter"
        }
      } else {
        useJUnitPlatform {
          includeTags "integration"
        }
      }
    } else {
      useJUnit {
        includeCategories 'org.apache.kafka.test.IntegrationTest'
      }
    }

    retry {
      maxRetries = userMaxTestRetries
      maxFailures = userMaxTestRetryFailures
    }
  }

  task unitTest(type: Test, dependsOn: compileJava) {
    maxParallelForks = maxTestForks
    ignoreFailures = userIgnoreFailures

    maxHeapSize = defaultMaxHeapSize
    jvmArgs = defaultJvmArgs

    testLogging {
      events = userTestLoggingEvents ?: testLoggingEvents
      showStandardStreams = userShowStandardStreams ?: testShowStandardStreams
      exceptionFormat = testExceptionFormat
      displayGranularity = 0
    }
    logTestStdout.rehydrate(delegate, owner, this)()

    exclude testsToExclude

    if (shouldUseJUnit5) {
      if (project.name == 'streams') {
        useJUnitPlatform {
          excludeTags "integration"
          excludeTags "org.apache.kafka.test.IntegrationTest"
	  // Both engines are needed to run JUnit 4 tests alongside JUnit 5 tests.
          // junit-vintage (JUnit 4) can be removed once the JUnit 4 migration is complete.
          includeEngines "junit-vintage", "junit-jupiter"
        }
      } else {
        useJUnitPlatform {
          excludeTags "integration"
        }
      }
    } else {
      useJUnit {
        excludeCategories 'org.apache.kafka.test.IntegrationTest'
      }
    }

    retry {
      maxRetries = userMaxTestRetries
      maxFailures = userMaxTestRetryFailures
    }
  }

  // remove test output from all test types
  tasks.withType(Test).all { t ->
    cleanTest {
      delete t.reports.junitXml.outputLocation
      delete t.reports.html.outputLocation
    }
  }

  jar {
    from "$rootDir/LICENSE"
    from "$rootDir/NOTICE"
  }

  task srcJar(type: Jar) {
    archiveClassifier = 'sources'
    from "$rootDir/LICENSE"
    from "$rootDir/NOTICE"
    from sourceSets.main.allSource
  }

  task javadocJar(type: Jar, dependsOn: javadoc) {
    archiveClassifier = 'javadoc'
    from "$rootDir/LICENSE"
    from "$rootDir/NOTICE"
    from javadoc.destinationDir
  }

  task docsJar(dependsOn: javadocJar)

  task systemTestLibs(dependsOn: jar)

  if (!sourceSets.test.allSource.isEmpty()) {
    task testJar(type: Jar) {
      archiveClassifier = 'test'
      from "$rootDir/LICENSE"
      from "$rootDir/NOTICE"
      from sourceSets.test.output
    }

    task testSrcJar(type: Jar, dependsOn: testJar) {
      archiveClassifier = 'test-sources'
      from "$rootDir/LICENSE"
      from "$rootDir/NOTICE"
      from sourceSets.test.allSource
    }

  }

  plugins.withType(ScalaPlugin) {

    scala {
      zincVersion = versions.zinc
    }

    task scaladocJar(type:Jar, dependsOn: scaladoc) {
      archiveClassifier = 'scaladoc'
      from "$rootDir/LICENSE"
      from "$rootDir/NOTICE"
      from scaladoc.destinationDir
    }

    //documentation task should also trigger building scala doc jar
    docsJar.dependsOn scaladocJar

  }

  tasks.withType(ScalaCompile) {

    scalaCompileOptions.keepAliveMode = userKeepAliveMode

    scalaCompileOptions.additionalParameters = [
      "-deprecation:false",
      "-unchecked",
      "-encoding", "utf8",
      "-Xlog-reflective-calls",
      "-feature",
      "-language:postfixOps",
      "-language:implicitConversions",
      "-language:existentials",
      "-Ybackend-parallelism", maxScalacThreads.toString(),
      "-Xlint:constant",
      "-Xlint:delayedinit-select",
      "-Xlint:doc-detached",
      "-Xlint:missing-interpolator",
      "-Xlint:nullary-unit",
      "-Xlint:option-implicit",
      "-Xlint:package-object-classes",
      "-Xlint:poly-implicit-overload",
      "-Xlint:private-shadow",
      "-Xlint:stars-align",
      "-Xlint:type-parameter-shadow",
      "-Xlint:unused"
    ]

    // See README.md for details on this option and the meaning of each value
    if (userScalaOptimizerMode.equals("method"))
      scalaCompileOptions.additionalParameters += ["-opt:l:method"]
    else if (userScalaOptimizerMode.startsWith("inline-")) {
      List<String> inlineFrom = ["-opt-inline-from:org.apache.kafka.**"]
      if (project.name.equals('core'))
        inlineFrom.add("-opt-inline-from:kafka.**")
      if (userScalaOptimizerMode.equals("inline-scala"))
        inlineFrom.add("-opt-inline-from:scala.**")

      scalaCompileOptions.additionalParameters += ["-opt:l:inline"]
      scalaCompileOptions.additionalParameters += inlineFrom
    }

    if (versions.baseScala != '2.12') {
      scalaCompileOptions.additionalParameters += ["-opt-warnings", "-Xlint:strict-unsealed-patmat"]
      // Scala 2.13.2 introduces compiler warnings suppression, which is a pre-requisite for -Xfatal-warnings
      scalaCompileOptions.additionalParameters += ["-Xfatal-warnings"]
    }

    // these options are valid for Scala versions < 2.13 only
    // Scala 2.13 removes them, see https://github.com/scala/scala/pull/6502 and https://github.com/scala/scala/pull/5969
    if (versions.baseScala == '2.12') {
      scalaCompileOptions.additionalParameters += [
        "-Xlint:by-name-right-associative",
        "-Xlint:nullary-override",
        "-Xlint:unsound-match"
      ]
    }

    // Scalac 2.12 `-release` requires Java 9 or higher, but Scala 2.13 doesn't have that restriction
    if (versions.baseScala == "2.13" || JavaVersion.current().isJava9Compatible())
      scalaCompileOptions.additionalParameters += ["-release", String.valueOf(minJavaVersion)]

    addParametersForTests(name, options)

    configure(scalaCompileOptions.forkOptions) {
      memoryMaximumSize = defaultMaxHeapSize
      jvmArgs = defaultJvmArgs
    }
  }

  checkstyle {
    configDirectory = rootProject.layout.projectDirectory.dir("checkstyle")
    configProperties = checkstyleConfigProperties("import-control.xml")
    toolVersion = versions.checkstyle
  }

  configure(checkstyleMain) {
    group = 'Verification'
    description = 'Run checkstyle on all main Java sources'
  }

  configure(checkstyleTest) {
    group = 'Verification'
    description = 'Run checkstyle on all test Java sources'
  }

  test.dependsOn('checkstyleMain', 'checkstyleTest')

  spotbugs {
    toolVersion = versions.spotbugs
    excludeFilter = file("$rootDir/gradle/spotbugs-exclude.xml")
    ignoreFailures = false
  }
  test.dependsOn('spotbugsMain')

  tasks.withType(com.github.spotbugs.snom.SpotBugsTask).configureEach {
    reports.configure {
      // Continue supporting `xmlFindBugsReport` for compatibility
      xml.enabled(project.hasProperty('xmlSpotBugsReport') || project.hasProperty('xmlFindBugsReport'))
      html.enabled(!project.hasProperty('xmlSpotBugsReport') && !project.hasProperty('xmlFindBugsReport'))
    }
    maxHeapSize = defaultMaxHeapSize
    jvmArgs = defaultJvmArgs
  }

  // Ignore core since its a scala project
  if (it.path != ':core') {
    if (userEnableTestCoverage) {
      apply plugin: "jacoco"

      jacoco {
        toolVersion = versions.jacoco
      }

      // NOTE: Jacoco Gradle plugin does not support "offline instrumentation" this means that classes mocked by PowerMock
      // may report 0 coverage, since the source was modified after initial instrumentation.
      // See https://github.com/jacoco/jacoco/issues/51
      jacocoTestReport {
        dependsOn tasks.test
        sourceSets sourceSets.main
        reports {
          html.required = true
          xml.required = true
          csv.required = false
        }
      }

    }
  }

  if (userEnableTestCoverage) {
    def coverageGen = it.path == ':core' ? 'reportTestScoverage' : 'jacocoTestReport'
    tasks.register('reportCoverage').configure { dependsOn(coverageGen) }
  }

  dependencyCheck {
    suppressionFile = "$rootDir/gradle/resources/dependencycheck-suppressions.xml"
    skipProjects = [ ":jmh-benchmarks", ":trogdor" ]
    skipConfigurations = [ "zinc" ]
  }
}

gradle.taskGraph.whenReady { taskGraph ->
  taskGraph.getAllTasks().findAll { it.name.contains('spotbugsScoverage') || it.name.contains('spotbugsTest') }.each { task ->
    task.enabled = false
  }
}

def fineTuneEclipseClasspathFile(eclipse, project) {
  eclipse.classpath.file {
    beforeMerged { cp ->
      cp.entries.clear()
      // for the core project add the directories defined under test/scala as separate source directories
      if (project.name.equals('core')) {
        cp.entries.add(new org.gradle.plugins.ide.eclipse.model.SourceFolder("src/test/scala/integration", null))
        cp.entries.add(new org.gradle.plugins.ide.eclipse.model.SourceFolder("src/test/scala/other", null))
        cp.entries.add(new org.gradle.plugins.ide.eclipse.model.SourceFolder("src/test/scala/unit", null))
      }
    }
    whenMerged { cp ->
      // for the core project exclude the separate sub-directories defined under test/scala. These are added as source dirs above
      if (project.name.equals('core')) {
        cp.entries.findAll { it.kind == "src" && it.path.equals("src/test/scala") }*.excludes = ["integration/", "other/", "unit/"]
      }
      /*
       * Set all eclipse build output to go to 'build_eclipse' directory. This is to ensure that gradle and eclipse use different
       * build output directories, and also avoid using the eclipse default of 'bin' which clashes with some of our script directories.
       * https://discuss.gradle.org/t/eclipse-generated-files-should-be-put-in-the-same-place-as-the-gradle-generated-files/6986/2
       */
      cp.entries.findAll { it.kind == "output" }*.path = "build_eclipse"
      /*
       * Some projects have explicitly added test output dependencies. These are required for the gradle build but not required
       * in Eclipse since the dependent projects are added as dependencies. So clean up these from the generated classpath.
       */
      cp.entries.removeAll { it.kind == "lib" && it.path.matches(".*/build/(classes|resources)/test") }
    }
  }
}

def checkstyleConfigProperties(configFileName) {
  [importControlFile: "$configFileName"]
}

if (userEnableTestCoverage) {
  tasks.register('reportCoverage').configure { dependsOn(subprojects.reportCoverage) }
}

def connectPkgs = [
    'connect:api',
    'connect:basic-auth-extension',
    'connect:file',
    'connect:json',
    'connect:runtime',
    'connect:test-plugins',
    'connect:transforms',
    'connect:mirror',
    'connect:mirror-client'
]

tasks.create(name: "jarConnect", dependsOn: connectPkgs.collect { it + ":jar" }) {}

tasks.create(name: "testConnect", dependsOn: connectPkgs.collect { it + ":test" }) {}

project(':generator') {
  dependencies {
    implementation libs.argparse4j
    implementation libs.jacksonDatabind
    implementation libs.jacksonJDK8Datatypes
    implementation libs.jacksonJaxrsJsonProvider
    testImplementation libs.junitJupiter
  }

  javadoc {
    enabled = false
  }
}

project(':clients') {
  base {
    archivesName = "kafka-clients"
  }

  configurations {
    generator
    shadowed
  }

  dependencies {
    implementation libs.zstd
    implementation libs.lz4
    implementation libs.snappy
    implementation libs.slf4jApi
    implementation libs.opentelemetryProto

    // libraries which should be added as runtime dependencies in generated pom.xml should be defined here:
    shadowed libs.zstd
    shadowed libs.lz4
    shadowed libs.snappy
    shadowed libs.slf4jApi

    compileOnly libs.jacksonDatabind // for SASL/OAUTHBEARER bearer token parsing
    compileOnly libs.jacksonJDK8Datatypes
    compileOnly libs.jose4j          // for SASL/OAUTHBEARER JWT validation; only used by broker

    testImplementation libs.bcpkix
    testImplementation libs.jacksonJaxrsJsonProvider
    testImplementation libs.jose4j
    testImplementation libs.junitJupiter
    testImplementation libs.log4j
    testImplementation libs.mockitoCore
    testImplementation libs.mockitoJunitJupiter // supports MockitoExtension

    testRuntimeOnly libs.slf4jlog4j
    testRuntimeOnly libs.jacksonDatabind
    testRuntimeOnly libs.jacksonJDK8Datatypes

    generator project(':generator')
  }

  task createVersionFile() {
    def receiptFile = file("$buildDir/kafka/$buildVersionFileName")
    inputs.property "commitId", commitId
    inputs.property "version", version
    outputs.file receiptFile

    doLast {
      def data = [
        commitId: commitId,
        version: version,
      ]

      receiptFile.parentFile.mkdirs()
      def content = data.entrySet().collect { "$it.key=$it.value" }.sort().join("\n")
      receiptFile.setText(content, "ISO-8859-1")
    }
  }

  shadowJar {
    dependsOn createVersionFile
    // archiveClassifier defines the classifier for the shadow jar, the default is 'all'.
    // We don't want to use the default classifier because it will cause the shadow jar to
    // overwrite the original jar. We also don't want to use the 'shadow' classifier because
    // it will cause the shadow jar to be named kafka-clients-shadow.jar. We want to use the
    // same name as the original jar, kafka-clients.jar.
    archiveClassifier = null
    // KIP-714: move shaded dependencies to a shaded location
    relocate('io.opentelemetry.proto', 'org.apache.kafka.shaded.io.opentelemetry.proto')
    relocate('com.google.protobuf', 'org.apache.kafka.shaded.com.google.protobuf')

    // dependencies excluded from the final jar, since they are declared as runtime dependencies
    dependencies {
      project.configurations.shadowed.allDependencies.each {
        exclude(dependency(it.group + ':' + it.name))
      }
      // exclude proto files from the jar
      exclude "**/opentelemetry/proto/**/*.proto"
      exclude "**/google/protobuf/*.proto"
    }

    from("$buildDir") {
      include "kafka/$buildVersionFileName"
    }

    from "$rootDir/LICENSE"
    from "$rootDir/NOTICE"
  }

  jar {
    enabled false
    dependsOn 'shadowJar'
  }

  clean.doFirst {
    delete "$buildDir/kafka/"
  }

  task processMessages(type:JavaExec) {
    mainClass = "org.apache.kafka.message.MessageGenerator"
    classpath = configurations.generator
    args = [ "-p", "org.apache.kafka.common.message",
             "-o", "src/generated/java/org/apache/kafka/common/message",
             "-i", "src/main/resources/common/message",
             "-t", "ApiMessageTypeGenerator",
             "-m", "MessageDataGenerator", "JsonConverterGenerator"
           ]
    inputs.dir("src/main/resources/common/message")
        .withPropertyName("messages")
        .withPathSensitivity(PathSensitivity.RELATIVE)
    outputs.cacheIf { true }
    outputs.dir("src/generated/java/org/apache/kafka/common/message")
  }

  task processMessagesRust(type:JavaExec) {
    mainClass = "org.apache.kafka.message.RustMessageGenerator"
    classpath = configurations.generator
    args = [ "-o", "../rust/src",
             "-i", "src/main/resources/common/message"
    ]
    inputs.dir("src/main/resources/common/message")
            .withPropertyName("messages")
            .withPathSensitivity(PathSensitivity.RELATIVE)
    outputs.cacheIf { true }
    outputs.dir("../rust/src")
  }

  task processTestMessages(type:JavaExec) {
    mainClass = "org.apache.kafka.message.MessageGenerator"
    classpath = configurations.generator
    args = [ "-p", "org.apache.kafka.common.message",
             "-o", "src/generated-test/java/org/apache/kafka/common/message",
             "-i", "src/test/resources/common/message",
             "-m", "MessageDataGenerator", "JsonConverterGenerator"
           ]
    inputs.dir("src/test/resources/common/message")
        .withPropertyName("testMessages")
        .withPathSensitivity(PathSensitivity.RELATIVE)
    outputs.cacheIf { true }
    outputs.dir("src/generated-test/java/org/apache/kafka/common/message")
  }

  sourceSets {
    main {
      java {
        srcDirs = ["src/generated/java", "src/main/java"]
      }
    }
    test {
      java {
        srcDirs = ["src/generated-test/java", "src/test/java"]
      }
    }
  }

  compileJava.dependsOn 'processMessages'
  srcJar.dependsOn 'processMessages'

  compileTestJava.dependsOn 'processTestMessages'

  javadoc {
    include "**/org/apache/kafka/clients/admin/*"
    include "**/org/apache/kafka/clients/consumer/*"
    include "**/org/apache/kafka/clients/producer/*"
    include "**/org/apache/kafka/common/*"
    include "**/org/apache/kafka/common/acl/*"
    include "**/org/apache/kafka/common/annotation/*"
    include "**/org/apache/kafka/common/errors/*"
    include "**/org/apache/kafka/common/header/*"
    include "**/org/apache/kafka/common/metrics/*"
    include "**/org/apache/kafka/common/metrics/stats/*"
    include "**/org/apache/kafka/common/quota/*"
    include "**/org/apache/kafka/common/resource/*"
    include "**/org/apache/kafka/common/serialization/*"
    include "**/org/apache/kafka/common/config/*"
    include "**/org/apache/kafka/common/config/provider/*"
    include "**/org/apache/kafka/common/security/auth/*"
    include "**/org/apache/kafka/common/security/plain/*"
    include "**/org/apache/kafka/common/security/scram/*"
    include "**/org/apache/kafka/common/security/token/delegation/*"
    include "**/org/apache/kafka/common/security/oauthbearer/*"
    include "**/org/apache/kafka/common/security/oauthbearer/secured/*"
    include "**/org/apache/kafka/server/authorizer/*"
    include "**/org/apache/kafka/server/policy/*"
    include "**/org/apache/kafka/server/quota/*"
    include "**/org/apache/kafka/server/telemetry/*"
  }
}

project(':java-tester') {
  apply plugin: 'application'

  checkstyle {
    ignoreFailures = true
    showViolations = false
  }

  spotbugs {
    ignoreFailures = true
  }

  dependencies {
    implementation project(':clients')
    implementation libs.jacksonDatabind
    implementation libs.commonsText
  }

  application {
    mainClass = 'me.ivanyu.java_tester.JavaTester'
  }
}

task aggregatedJavadoc(type: Javadoc, dependsOn: compileJava) {
  def projectsWithJavadoc = subprojects.findAll { it.javadoc.enabled }
  source = projectsWithJavadoc.collect { it.sourceSets.main.allJava }
  classpath = files(projectsWithJavadoc.collect { it.sourceSets.main.compileClasspath })
  includes = projectsWithJavadoc.collectMany { it.javadoc.getIncludes() }
  excludes = projectsWithJavadoc.collectMany { it.javadoc.getExcludes() }
}
