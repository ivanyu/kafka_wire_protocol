// Licensed to the Apache Software Foundation (ASF) under one or more
// contributor license agreements.  See the NOTICE file distributed with
// this work for additional information regarding copyright ownership.
// The ASF licenses this file to You under the Apache License, Version 2.0
// (the "License"); you may not use this file except in compliance with
// the License.  You may obtain a copy of the License at
//
//    http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

import org.ajoberstar.grgit.Grgit
import org.gradle.api.JavaVersion

import java.nio.charset.StandardCharsets

buildscript {
  repositories {
    mavenCentral()
  }
  apply from: "$rootDir/gradle/dependencies.gradle"

  dependencies {
    // For Apache Rat plugin to ignore non-Git files
    classpath "org.ajoberstar.grgit:grgit-core:$versions.grgit"
  }
}

plugins {
  id 'com.github.ben-manes.versions' version '0.48.0'
  id 'idea'
  id 'jacoco'
  id 'java-library'
  id 'org.owasp.dependencycheck' version '8.2.1'
  id 'org.nosphere.apache.rat' version "0.8.1"
  id "io.swagger.core.v3.swagger-gradle-plugin" version "${swaggerVersion}"

  id "com.github.spotbugs" version '6.0.25' apply false
  id 'org.scoverage' version '8.0.3' apply false
  // Updating the shadow plugin version to 8.1.1 causes issue with signing and publishing the shadowed
  // artifacts - see https://github.com/johnrengelman/shadow/issues/901
  id 'com.github.johnrengelman.shadow' version '8.1.0' apply false
  id 'com.diffplug.spotless' version "6.25.0"
}

ext {
  gradleVersion = versions.gradle
  minClientJavaVersion = 17
  minNonClientJavaVersion = 17
  modulesNeedingJava11 = [":clients", ":examples", ":generator", ":streams", ":streams:examples", ":streams:test-utils", ":streams-scala", ":test-common:test-common-util"]

  buildVersionFileName = "kafka-version.properties"

  defaultMaxHeapSize = "2g"
  defaultJvmArgs = ["-Xss4m", "-XX:+UseParallelGC"]

  // "JEP 403: Strongly Encapsulate JDK Internals" causes some tests to fail when they try
  // to access internals (often via mocking libraries). We use `--add-opens` as a workaround
  // for now and we'll fix it properly (where possible) via KAFKA-13275.
  if (JavaVersion.current().isCompatibleWith(JavaVersion.VERSION_16))
    defaultJvmArgs.addAll(
            "--add-opens=java.base/java.io=ALL-UNNAMED",
            "--add-opens=java.base/java.lang=ALL-UNNAMED",
            "--add-opens=java.base/java.nio=ALL-UNNAMED",
            "--add-opens=java.base/java.nio.file=ALL-UNNAMED",
            "--add-opens=java.base/java.util=ALL-UNNAMED",
            "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED",
            "--add-opens=java.base/java.util.regex=ALL-UNNAMED",
            "--add-opens=java.base/java.util.stream=ALL-UNNAMED",
            "--add-opens=java.base/java.text=ALL-UNNAMED",
            "--add-opens=java.base/java.time=ALL-UNNAMED",
            "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED"
    )

  maxTestForks = project.hasProperty('maxParallelForks') ? maxParallelForks.toInteger() : Runtime.runtime.availableProcessors()
  maxScalacThreads = project.hasProperty('maxScalacThreads') ? maxScalacThreads.toInteger() :
          Math.min(Runtime.runtime.availableProcessors(), 8)
  userIgnoreFailures = project.hasProperty('ignoreFailures') ? ignoreFailures.toBoolean() : false

  userMaxTestRetries = project.hasProperty('maxTestRetries') ? maxTestRetries.toInteger() : 0
  userMaxTestRetryFailures = project.hasProperty('maxTestRetryFailures') ? maxTestRetryFailures.toInteger() : 0

  userMaxQuarantineTestRetries = project.hasProperty('maxQuarantineTestRetries') ? maxQuarantineTestRetries.toInteger() : 0
  userMaxQuarantineTestRetryFailures = project.hasProperty('maxQuarantineTestRetryFailures') ? maxQuarantineTestRetryFailures.toInteger() : 0

  skipSigning = project.hasProperty('skipSigning') && skipSigning.toBoolean()
  shouldSign = !skipSigning && !version.endsWith("SNAPSHOT")

  mavenUrl = project.hasProperty('mavenUrl') ? project.mavenUrl : ''
  mavenUsername = project.hasProperty('mavenUsername') ? project.mavenUsername : ''
  mavenPassword = project.hasProperty('mavenPassword') ? project.mavenPassword : ''

  userShowStandardStreams = project.hasProperty("showStandardStreams") ? showStandardStreams : null

  userTestLoggingEvents = project.hasProperty("testLoggingEvents") ? Arrays.asList(testLoggingEvents.split(",")) : null

  userEnableTestCoverage = project.hasProperty("enableTestCoverage") ? enableTestCoverage : false

  userKeepAliveModeString = project.hasProperty("keepAliveMode") ? keepAliveMode : "daemon"
  userKeepAliveMode = KeepAliveMode.values().find(m -> m.name().toLowerCase().equals(userKeepAliveModeString))
  if (userKeepAliveMode == null) {
    def keepAliveValues = KeepAliveMode.values().collect(m -> m.name.toLowerCase())
    throw new GradleException("Unexpected value for keepAliveMode property. Expected one of $keepAliveValues, but received: $userKeepAliveModeString")
  }

  // See README.md for details on this option and the reasoning for the default
  userScalaOptimizerMode = project.hasProperty("scalaOptimizerMode") ? scalaOptimizerMode : "inline-kafka"
  def scalaOptimizerValues = ["none", "method", "inline-kafka", "inline-scala"]
  if (!scalaOptimizerValues.contains(userScalaOptimizerMode))
    throw new GradleException("Unexpected value for scalaOptimizerMode property. Expected one of $scalaOptimizerValues, but received: $userScalaOptimizerMode")

  generatedDocsDir = new File("${project.rootDir}/docs/generated")
  repo = file("$rootDir/.git").isDirectory() ? Grgit.open(currentDir: project.getRootDir()) : null

  commitId = determineCommitId()

  configureJavaCompiler = { name, options, projectPath ->
    // -parameters generates arguments with parameter names in TestInfo#getDisplayName.
    // ref: https://github.com/junit-team/junit5/blob/4c0dddad1b96d4a20e92a2cd583954643ac56ac0/junit-jupiter-params/src/main/java/org/junit/jupiter/params/ParameterizedTest.java#L161-L164

    def releaseVersion = modulesNeedingJava11.any { projectPath == it } ? minClientJavaVersion : minNonClientJavaVersion

    options.compilerArgs << "-encoding" << "UTF-8"
    options.release = releaseVersion

    if (name in ["compileTestJava", "compileTestScala"]) {
      options.compilerArgs << "-parameters"
    } else if (name in ["compileJava", "compileScala"]) {
      options.compilerArgs << "-Xlint:-rawtypes"
      options.compilerArgs << "-Xlint:all"
      options.compilerArgs << "-Xlint:-serial"
      options.compilerArgs << "-Xlint:-try"
      options.compilerArgs << "-Werror"
    }
  }

  runtimeTestLibs = [
          libs.slf4jLog4j2,
          libs.junitPlatformLanucher,
          libs.jacksonDatabindYaml,
  ]

  log4jReleaseLibs = [
          libs.slf4jLog4j2,
          libs.log4j1Bridge2Api,
          libs.jacksonDatabindYaml
  ]

  log4j2Libs = [
          libs.log4j2Api,
          libs.log4j2Core
  ]

  testLog4j2Libs = [
          libs.slf4jApi,
          libs.slf4jLog4j2,
          libs.log4j2Api,
          libs.log4j2Core
  ]
}

allprojects {

  repositories {
    mavenCentral()
  }

  dependencyUpdates {
    revision="release"
    resolutionStrategy {
      componentSelection { rules ->
        rules.all { ComponentSelection selection ->
          boolean rejected = ['snap', 'alpha', 'beta', 'rc', 'cr', 'm'].any { qualifier ->
            selection.candidate.version ==~ /(?i).*[.-]${qualifier}[.\d-]*/
          }
          if (rejected) {
            selection.reject('Release candidate')
          }
        }
      }
    }
  }

  configurations.all {
    // zinc is the Scala incremental compiler, it has a configuration for its own dependencies
    // that are unrelated to the project dependencies, we should not change them
    if (name != "zinc") {
      resolutionStrategy {
        force(
                // be explicit about the javassist dependency version instead of relying on the transitive version
                libs.javassist,
                // ensure we have a single version in the classpath despite transitive dependencies
                libs.scalaLibrary,
                libs.scalaReflect,
                libs.jacksonAnnotations
        )
      }
    }
  }
  task printAllDependencies(type: DependencyReportTask) {}

  tasks.withType(Javadoc) {
    options.charSet = 'UTF-8'
    options.docEncoding = 'UTF-8'
    options.encoding = 'UTF-8'
    options.memberLevel = JavadocMemberLevel.PUBLIC  // Document only public members/API
    // Turn off doclint for now, see https://blog.joda.org/2014/02/turning-off-doclint-in-jdk-8-javadoc.html for rationale
    options.addStringOption('Xdoclint:none', '-quiet')
    // Javadoc warnings should fail the build in JDK 15+ https://bugs.openjdk.org/browse/JDK-8200363
    options.addBooleanOption('Werror', JavaVersion.current().isCompatibleWith(JavaVersion.VERSION_15))
    options.links "https://docs.oracle.com/en/java/javase/${JavaVersion.current().majorVersion}/docs/api/"
  }

  tasks.withType(Checkstyle) {
    minHeapSize = "200m"
    maxHeapSize = "1g"
  }

  clean {
    delete "${projectDir}/src/generated"
    delete "${projectDir}/src/generated-test"
  }
}

def determineCommitId() {
  def takeFromHash = 16
  if (project.hasProperty('commitId')) {
    commitId.take(takeFromHash)
  } else if (repo != null) {
    repo.head().id.take(takeFromHash)
  } else {
    "unknown"
  }
}

/**
 * For a given Project, compute a nice dash separated directory name
 * to store the JUnit XML files in. E.g., Project ":connect:api" -> "connect-api"
 */
static def projectToJUnitXmlPath(project) {
  var p = project
  var projectNames = []
  while (p != null) {
    projectNames.push(p.name)
    p = p.parent
    if (p.name == "kafka") {
      break;
    }
  }
  return projectNames.join("/")
}


apply from: file('wrapper.gradle')

if (repo != null) {
  rat {
    dependsOn subprojects.collect {
      it.tasks.matching {
        it.name == "processMessages" || it.name == "processTestMessages"
      }
    }

    verbose.set(true)
    reportDir.set(project.file('build/rat'))
    stylesheet.set(file('gradle/resources/rat-output-to-html.xsl'))

    // Exclude everything under the directory that git should be ignoring via .gitignore or that isn't checked in. These
    // restrict us only to files that are checked in or are staged.
    excludes = new ArrayList<String>(repo.clean(ignore: false, directories: true, dryRun: true))
    // And some of the files that we have checked in should also be excluded from this check
    excludes.addAll([
            '**/.git/**',
            '**/build/**',
            'CONTRIBUTING.md',
            'PULL_REQUEST_TEMPLATE.md',
            'gradlew',
            'gradlew.bat',
            'gradle/wrapper/gradle-wrapper.properties',
            'trogdor/README.md',
            '**/README.md',
            '**/id_rsa',
            '**/id_rsa.pub',
            'checkstyle/suppressions.xml',
            'streams/quickstart/java/src/test/resources/projects/basic/goal.txt',
            'streams/streams-scala/logs/*',
            'licenses/*',
            '**/generated/**',
            'clients/src/test/resources/serializedData/*',
            'docker/test/fixtures/secrets/*',
            'docker/examples/fixtures/secrets/*',
            'docker/docker_official_images/.gitkeep'
    ])
  }
} else {
  rat.enabled = false
}
println("Starting build with version $version (commit id ${commitId == null ? "null" : commitId.take(8)}) using Gradle $gradleVersion, Java ${JavaVersion.current()} and Scala ${versions.scala}")
println("Build properties: ignoreFailures=$userIgnoreFailures, maxParallelForks=$maxTestForks, maxScalacThreads=$maxScalacThreads, maxTestRetries=$userMaxTestRetries")

subprojects {

  // enable running :dependencies task recursively on all subprojects
  // eg: ./gradlew allDeps
  task allDeps(type: DependencyReportTask) {}
  // enable running :dependencyInsight task recursively on all subprojects
  // eg: ./gradlew allDepInsight --configuration runtime --dependency com.fasterxml.jackson.core:jackson-databind
  task allDepInsight(type: DependencyInsightReportTask) {showingAllVariants = false} doLast {}

  apply plugin: 'java-library'
  apply plugin: 'checkstyle'
  apply plugin: "com.github.spotbugs"

  // We use the shadow plugin for the jmh-benchmarks module and the `-all` jar can get pretty large, so
  // don't publish it
  def shouldPublish = !project.name.equals('jmh-benchmarks')
  def shouldPublishWithShadow = (['clients'].contains(project.name))

  if (shouldPublish) {
    apply plugin: 'maven-publish'
    apply plugin: 'signing'

    // Add aliases for the task names used by the maven plugin for backwards compatibility
    // The maven plugin was replaced by the maven-publish plugin in Gradle 7.0
    tasks.register('install').configure { dependsOn(publishToMavenLocal) }
    tasks.register('uploadArchives').configure { dependsOn(publish) }
  }

  // apply the eclipse plugin only to subprojects that hold code. 'connect' is just a folder.
  if (!project.name.equals('connect')) {
    apply plugin: 'eclipse'
    fineTuneEclipseClasspathFile(eclipse, project)
  }

  java {
    consistentResolution {
      // resolve the compileClasspath and then "inject" the result of resolution as strict constraints into the runtimeClasspath
      useCompileClasspathVersions()
    }
  }

  tasks.withType(JavaCompile) {
    configureJavaCompiler(name, options, project.path)
  }

  if (shouldPublish) {

    publishing {
      repositories {
        // To test locally, invoke gradlew with `-PmavenUrl=file:///some/local/path`
        maven {
          url = mavenUrl
          credentials {
            username = mavenUsername
            password = mavenPassword
          }
        }
      }
      publications {
        mavenJava(MavenPublication) {
          if (!shouldPublishWithShadow) {
            from components.java
          } else {
            apply plugin: 'com.github.johnrengelman.shadow'
            project.shadow.component(mavenJava)

            // Fix for avoiding inclusion of runtime dependencies marked as 'shadow' in MANIFEST Class-Path.
            // https://github.com/johnrengelman/shadow/issues/324
            afterEvaluate {
              pom.withXml { xml ->
                if (xml.asNode().get('dependencies') == null) {
                  xml.asNode().appendNode('dependencies')
                }
                def dependenciesNode = xml.asNode().get('dependencies').get(0)
                project.configurations.shadowed.allDependencies.each {
                  def dependencyNode = dependenciesNode.appendNode('dependency')
                  dependencyNode.appendNode('groupId', it.group)
                  dependencyNode.appendNode('artifactId', it.name)
                  dependencyNode.appendNode('version', it.version)
                  dependencyNode.appendNode('scope', 'runtime')
                }
              }
            }
          }

          afterEvaluate {
            ["srcJar", "javadocJar", "scaladocJar", "testJar", "testSrcJar"].forEach { taskName ->
              def task = tasks.findByName(taskName)
              if (task != null)
                artifact task
            }

            artifactId = base.archivesName.get()
            pom {
              name = 'Apache Kafka'
              url = 'https://kafka.apache.org'
              licenses {
                license {
                  name = 'The Apache License, Version 2.0'
                  url = 'http://www.apache.org/licenses/LICENSE-2.0.txt'
                  distribution = 'repo'
                }
              }
            }
          }
        }
      }
    }

    if (shouldSign) {
      signing {
        sign publishing.publications.mavenJava
      }
    }
  }

  def testLoggingEvents = ["passed", "skipped", "failed"]
  def testShowStandardStreams = false
  def testExceptionFormat = 'full'
  // Gradle built-in logging only supports sending test output to stdout, which generates a lot
  // of noise, especially for passing tests. We really only want output for failed tests. This
  // hooks into the output and logs it (so we don't have to buffer it all in memory) and only
  // saves the output for failing tests. Directory and filenames are such that you can, e.g.,
  // create a Jenkins rule to collect failed test output.
  def logTestStdout = {
    def testId = { TestDescriptor descriptor ->
      "${descriptor.className}.${descriptor.name}".toString()
    }

    def logFiles = new HashMap<String, File>()
    def logStreams = new HashMap<String, FileOutputStream>()
    beforeTest { TestDescriptor td ->
      def tid = testId(td)
      // truncate the file name if it's too long
      def logFile = new File(
              "${projectDir}/build/reports/testOutput/${tid.substring(0, Math.min(tid.size(),240))}.test.stdout"
      )
      logFile.parentFile.mkdirs()
      logFiles.put(tid, logFile)
      logStreams.put(tid, new FileOutputStream(logFile))
    }
    onOutput { TestDescriptor td, TestOutputEvent toe ->
      def tid = testId(td)
      // Some output can happen outside the context of a specific test (e.g. at the class level)
      // and beforeTest/afterTest seems to not be invoked for these cases (and similarly, there's
      // a TestDescriptor hierarchy that includes the thread executing the test, Gradle tasks,
      // etc). We see some of these in practice and it seems like something buggy in the Gradle
      // test runner since we see it *before* any tests and it is frequently not related to any
      // code in the test (best guess is that it is tail output from last test). We won't have
      // an output file for these, so simply ignore them. If they become critical for debugging,
      // they can be seen with showStandardStreams.
      if (td.name == td.className || td.className == null) {
        // silently ignore output unrelated to specific test methods
        return
      } else if (logStreams.get(tid) == null) {
        println "WARNING: unexpectedly got output for a test [${tid}]" +
                " that we didn't previously see in the beforeTest hook." +
                " Message for debugging: [" + toe.message + "]."
        return
      }
      try {
        logStreams.get(tid).write(toe.message.getBytes(StandardCharsets.UTF_8))
      } catch (Exception e) {
        println "ERROR: Failed to write output for test ${tid}"
        e.printStackTrace()
      }
    }
    afterTest { TestDescriptor td, TestResult tr ->
      def tid = testId(td)
      try {
        logStreams.get(tid).close()
        if (tr.resultType != TestResult.ResultType.FAILURE) {
          logFiles.get(tid).delete()
        } else {
          def file = logFiles.get(tid)
          println "${tid} failed, log available in ${file}"
        }
      } catch (Exception e) {
        println "ERROR: Failed to close stdout file for ${tid}"
        e.printStackTrace()
      } finally {
        logFiles.remove(tid)
        logStreams.remove(tid)
      }
    }
  }

  // The suites are for running sets of tests in IDEs.
  // Gradle will run each test class, so we exclude the suites to avoid redundantly running the tests twice.
  def testsToExclude = ['**/*Suite.class']

  test {
    ext {
      isGithubActions = System.getenv('GITHUB_ACTIONS') != null
      hadFailure = false  // Used to track if any tests failed, see afterSuite below
    }

    maxParallelForks = maxTestForks
    ignoreFailures = userIgnoreFailures || ext.isGithubActions

    maxHeapSize = defaultMaxHeapSize
    jvmArgs = defaultJvmArgs

    // KAFKA-17433 Used by deflake.yml github action to repeat individual tests
    systemProperty("kafka.cluster.test.repeat", project.findProperty("kafka.cluster.test.repeat"))
    systemProperty("kafka.test.catalog.file", project.findProperty("kafka.test.catalog.file"))
    systemProperty("kafka.test.run.quarantined", "false")

    testLogging {
      events = userTestLoggingEvents ?: testLoggingEvents
      showStandardStreams = userShowStandardStreams ?: testShowStandardStreams
      exceptionFormat = testExceptionFormat
      displayGranularity = 0
    }
    logTestStdout.rehydrate(delegate, owner, this)()

    exclude testsToExclude

    useJUnitPlatform {
      includeEngines 'junit-jupiter'
      excludeTags 'flaky'
    }

    develocity {
      testRetry {
        maxRetries = userMaxTestRetries
        maxFailures = userMaxTestRetryFailures
      }
    }

    // As we process results, check if there were any test failures.
    afterSuite { desc, result ->
      if (result.resultType == TestResult.ResultType.FAILURE) {
        ext.hadFailure = true
      }
    }

    // This closure will copy JUnit XML files out of the sub-project's build directory and into
    // a top-level build/junit-xml directory. This is necessary to avoid reporting on tests which
    // were not run, but instead were restored via FROM-CACHE. See KAFKA-17479 for more details.
    doLast {
      if (ext.isGithubActions) {
        def moduleDirPath = projectToJUnitXmlPath(project)
        def dest = rootProject.layout.buildDirectory.dir("junit-xml/${moduleDirPath}/test").get().asFile
        println "Copy JUnit XML for ${project.name} to $dest"
        ant.copy(todir: "$dest") {
          ant.fileset(dir: "${test.reports.junitXml.entryPoint}")
        }

        // If there were any test failures, we want to fail the task to prevent the failures
        // from being cached.
        if (ext.hadFailure) {
          throw new GradleException("Failing this task since '${project.name}:${name}' had test failures.")
        }
      }
    }
  }

  task quarantinedTest(type: Test, dependsOn: compileJava) {
    ext {
      isGithubActions = System.getenv('GITHUB_ACTIONS') != null
      hadFailure = false  // Used to track if any tests failed, see afterSuite below
    }

    // Disable caching and up-to-date for this task. We always want quarantined tests
    // to run and never want to cache their results. Since we do this, we can avoid
    // explicitly failing the build like we do in "test" with ext.hadFailure.
    outputs.upToDateWhen { false }
    outputs.cacheIf { false }

    maxParallelForks = maxTestForks
    ignoreFailures = userIgnoreFailures || ext.isGithubActions

    maxHeapSize = defaultMaxHeapSize
    jvmArgs = defaultJvmArgs

    // KAFKA-17433 Used by deflake.yml github action to repeat individual tests
    systemProperty("kafka.cluster.test.repeat", project.findProperty("kafka.cluster.test.repeat"))
    systemProperty("kafka.test.catalog.file", project.findProperty("kafka.test.catalog.file"))
    systemProperty("kafka.test.run.quarantined", "true")

    testLogging {
      events = userTestLoggingEvents ?: testLoggingEvents
      showStandardStreams = userShowStandardStreams ?: testShowStandardStreams
      exceptionFormat = testExceptionFormat
      displayGranularity = 0
    }
    logTestStdout.rehydrate(delegate, owner, this)()

    useJUnitPlatform {
      includeEngines 'junit-jupiter'
    }

    develocity {
      testRetry {
        maxRetries = userMaxQuarantineTestRetries
        maxFailures = userMaxQuarantineTestRetryFailures
      }
    }

    // As we process results, check if there were any test failures.
    afterSuite { desc, result ->
      if (result.resultType == TestResult.ResultType.FAILURE) {
        ext.hadFailure = true
      }
    }

    // This closure will copy JUnit XML files out of the sub-project's build directory and into
    // a top-level build/junit-xml directory. This is necessary to avoid reporting on tests which
    // were not run, but instead were restored via FROM-CACHE. See KAFKA-17479 for more details.
    doLast {
      if (ext.isGithubActions) {
        def moduleDirPath = projectToJUnitXmlPath(project)
        def dest = rootProject.layout.buildDirectory.dir("junit-xml/${moduleDirPath}/quarantinedTest").get().asFile
        println "Copy JUnit XML for ${project.name} to $dest"
        ant.copy(todir: "$dest", failonerror: "false") {
          ant.fileset(dir: "${quarantinedTest.reports.junitXml.entryPoint}") {
            ant.include(name: "**/*.xml")
          }
        }
        // If there were any test failures, we want to fail the task to prevent the failures
        // from being cached.
        if (ext.hadFailure) {
          throw new GradleException("Failing this task since '${project.name}:${name}' had test failures.")
        }
      }
    }
  }

  task integrationTest(type: Test, dependsOn: compileJava) {
    maxParallelForks = maxTestForks
    ignoreFailures = userIgnoreFailures

    // Increase heap size for integration tests
    maxHeapSize = "2560m"
    jvmArgs = defaultJvmArgs


    testLogging {
      events = userTestLoggingEvents ?: testLoggingEvents
      showStandardStreams = userShowStandardStreams ?: testShowStandardStreams
      exceptionFormat = testExceptionFormat
      displayGranularity = 0
    }
    logTestStdout.rehydrate(delegate, owner, this)()

    exclude testsToExclude

    useJUnitPlatform {
      includeTags "integration"
      includeEngines 'junit-jupiter'
    }

    develocity {
      testRetry {
        maxRetries = userMaxTestRetries
        maxFailures = userMaxTestRetryFailures
      }
    }
  }

  task unitTest(type: Test, dependsOn: compileJava) {
    maxParallelForks = maxTestForks
    ignoreFailures = userIgnoreFailures

    maxHeapSize = defaultMaxHeapSize
    jvmArgs = defaultJvmArgs

    testLogging {
      events = userTestLoggingEvents ?: testLoggingEvents
      showStandardStreams = userShowStandardStreams ?: testShowStandardStreams
      exceptionFormat = testExceptionFormat
      displayGranularity = 0
    }
    logTestStdout.rehydrate(delegate, owner, this)()

    exclude testsToExclude

    useJUnitPlatform {
      excludeTags "integration"
      includeEngines 'junit-jupiter'
    }

    develocity {
      testRetry {
        maxRetries = userMaxTestRetries
        maxFailures = userMaxTestRetryFailures
      }
    }
  }

  // remove test output from all test types
  tasks.withType(Test).all { t ->
    cleanTest {
      delete t.reports.junitXml.outputLocation
      delete t.reports.html.outputLocation
    }
  }

  jar {
    from "$rootDir/LICENSE"
    from "$rootDir/NOTICE"
  }

  task srcJar(type: Jar) {
    archiveClassifier = 'sources'
    from "$rootDir/LICENSE"
    from "$rootDir/NOTICE"
    from sourceSets.main.allSource
  }

  task javadocJar(type: Jar, dependsOn: javadoc) {
    archiveClassifier = 'javadoc'
    from "$rootDir/LICENSE"
    from "$rootDir/NOTICE"
    from javadoc.destinationDir
  }

  task docsJar(dependsOn: javadocJar)

  test.dependsOn('javadoc')

  task systemTestLibs(dependsOn: jar)

  if (!sourceSets.test.allSource.isEmpty()) {
    task testJar(type: Jar) {
      archiveClassifier = 'test'
      from "$rootDir/LICENSE"
      from "$rootDir/NOTICE"
      from sourceSets.test.output
      // The junit-platform.properties file is used for configuring and customizing the behavior of the JUnit platform.
      // It should only apply to Kafka's own JUnit tests, and should not exist in the test JAR.
      // If we include it in the test JAR, it could lead to conflicts with user configurations.
      exclude 'junit-platform.properties'
    }

    task testSrcJar(type: Jar, dependsOn: testJar) {
      archiveClassifier = 'test-sources'
      from "$rootDir/LICENSE"
      from "$rootDir/NOTICE"
      from sourceSets.test.allSource
    }

  }

  plugins.withType(ScalaPlugin) {

    scala {
      zincVersion = versions.zinc
    }

    task scaladocJar(type:Jar, dependsOn: scaladoc) {
      archiveClassifier = 'scaladoc'
      from "$rootDir/LICENSE"
      from "$rootDir/NOTICE"
      from scaladoc.destinationDir
    }

    //documentation task should also trigger building scala doc jar
    docsJar.dependsOn scaladocJar

  }

  tasks.withType(ScalaCompile) {
    def releaseVersion = modulesNeedingJava11.any { project.path == it } ? minClientJavaVersion : minNonClientJavaVersion
    scalaCompileOptions.keepAliveMode = userKeepAliveMode

    scalaCompileOptions.additionalParameters = [
            "-deprecation:false",
            "-unchecked",
            "-encoding", "utf8",
            "-Xlog-reflective-calls",
            "-feature",
            "-language:postfixOps",
            "-language:implicitConversions",
            "-language:existentials",
            "-Ybackend-parallelism", maxScalacThreads.toString(),
            "-Xlint:constant",
            "-Xlint:delayedinit-select",
            "-Xlint:doc-detached",
            "-Xlint:missing-interpolator",
            "-Xlint:nullary-unit",
            "-Xlint:option-implicit",
            "-Xlint:package-object-classes",
            "-Xlint:poly-implicit-overload",
            "-Xlint:private-shadow",
            "-Xlint:stars-align",
            "-Xlint:type-parameter-shadow",
            "-Xlint:unused"
    ]

    // See README.md for details on this option and the meaning of each value
    if (userScalaOptimizerMode.equals("method"))
      scalaCompileOptions.additionalParameters += ["-opt:l:method"]
    else if (userScalaOptimizerMode.startsWith("inline-")) {
      List<String> inlineFrom = ["-opt-inline-from:org.apache.kafka.**"]
      if (project.name.equals('core'))
        inlineFrom.add("-opt-inline-from:kafka.**")
      if (userScalaOptimizerMode.equals("inline-scala"))
        inlineFrom.add("-opt-inline-from:scala.**")

      scalaCompileOptions.additionalParameters += ["-opt:l:inline"]
      scalaCompileOptions.additionalParameters += inlineFrom
    }

    scalaCompileOptions.additionalParameters += ["-opt-warnings", "-Xlint:strict-unsealed-patmat"]
    // Scala 2.13.2 introduces compiler warnings suppression, which is a pre-requisite for -Xfatal-warnings
    scalaCompileOptions.additionalParameters += ["-Xfatal-warnings"]
    scalaCompileOptions.additionalParameters += ["--release", String.valueOf(releaseVersion)]

    // Gradle does not support the `release` configuration when performing joint Java-Scala compilation.
    // For more details, refer to https://github.com/gradle/gradle/issues/13762.
    // As a result, we need to explicitly configure the Scala compiler with this setting.
    options.compilerArgs += ["--release", String.valueOf(releaseVersion)]

    configureJavaCompiler(name, options, project.path)

    configure(scalaCompileOptions.forkOptions) {
      memoryMaximumSize = defaultMaxHeapSize
      jvmArgs = defaultJvmArgs
    }
  }

  checkstyle {
    configDirectory = rootProject.layout.projectDirectory.dir("checkstyle")
    configProperties = checkstyleConfigProperties("import-control.xml")
    toolVersion = versions.checkstyle
  }

  configure(checkstyleMain) {
    group = 'Verification'
    description = 'Run checkstyle on all main Java sources'
  }

  configure(checkstyleTest) {
    group = 'Verification'
    description = 'Run checkstyle on all test Java sources'
  }

  test.dependsOn('checkstyleMain', 'checkstyleTest')

  spotbugs {
    toolVersion = versions.spotbugs
    excludeFilter = file("$rootDir/gradle/spotbugs-exclude.xml")
    ignoreFailures = false
  }
  test.dependsOn('spotbugsMain')

  tasks.withType(com.github.spotbugs.snom.SpotBugsTask).configureEach {
    reports.configure {
      // Continue supporting `xmlFindBugsReport` for compatibility
      xml.enabled(project.hasProperty('xmlSpotBugsReport') || project.hasProperty('xmlFindBugsReport'))
      html.enabled(!project.hasProperty('xmlSpotBugsReport') && !project.hasProperty('xmlFindBugsReport'))
    }
    maxHeapSize = defaultMaxHeapSize
    jvmArgs = defaultJvmArgs
  }

  // Ignore core since its a scala project
  if (it.path != ':core') {
    if (userEnableTestCoverage) {
      apply plugin: "jacoco"

      jacoco {
        toolVersion = versions.jacoco
      }

      jacocoTestReport {
        dependsOn tasks.test
        sourceSets sourceSets.main
        reports {
          html.required = true
          xml.required = true
          csv.required = false
        }
      }

    }
  }

  if (userEnableTestCoverage) {
    def coverageGen = it.path == ':core' ? 'reportTestScoverage' : 'jacocoTestReport'
    tasks.register('reportCoverage').configure { dependsOn(coverageGen) }
  }

  dependencyCheck {
    suppressionFile = "$rootDir/gradle/resources/dependencycheck-suppressions.xml"
    skipProjects = [ ":jmh-benchmarks", ":trogdor" ]
    skipConfigurations = [ "zinc" ]
  }
  apply plugin: 'com.diffplug.spotless'
  spotless {
    java {
      targetExclude('**/generated/**/*.java','**/generated-test/**/*.java')
      importOrder('kafka', 'org.apache.kafka', 'com', 'net', 'org', 'java', 'javax', '', '\\#')
      removeUnusedImports()
    }
  }
}

gradle.taskGraph.whenReady { taskGraph ->
  taskGraph.getAllTasks().findAll { it.name.contains('spotbugsScoverage') || it.name.contains('spotbugsTest') }.each { task ->
    task.enabled = false
  }
}

def fineTuneEclipseClasspathFile(eclipse, project) {
  eclipse.classpath.file {
    beforeMerged { cp ->
      cp.entries.clear()
      // for the core project add the directories defined under test/scala as separate source directories
      if (project.name.equals('core')) {
        cp.entries.add(new org.gradle.plugins.ide.eclipse.model.SourceFolder("src/test/scala/integration", null))
        cp.entries.add(new org.gradle.plugins.ide.eclipse.model.SourceFolder("src/test/scala/other", null))
        cp.entries.add(new org.gradle.plugins.ide.eclipse.model.SourceFolder("src/test/scala/unit", null))
      }
    }
    whenMerged { cp ->
      // for the core project exclude the separate sub-directories defined under test/scala. These are added as source dirs above
      if (project.name.equals('core')) {
        cp.entries.findAll { it.kind == "src" && it.path.equals("src/test/scala") }*.excludes = ["integration/", "other/", "unit/"]
      }
      /*
       * Set all eclipse build output to go to 'build_eclipse' directory. This is to ensure that gradle and eclipse use different
       * build output directories, and also avoid using the eclipse default of 'bin' which clashes with some of our script directories.
       * https://discuss.gradle.org/t/eclipse-generated-files-should-be-put-in-the-same-place-as-the-gradle-generated-files/6986/2
       */
      cp.entries.findAll { it.kind == "output" }*.path = "build_eclipse"
      /*
       * Some projects have explicitly added test output dependencies. These are required for the gradle build but not required
       * in Eclipse since the dependent projects are added as dependencies. So clean up these from the generated classpath.
       */
      cp.entries.removeAll { it.kind == "lib" && it.path.matches(".*/build/(classes|resources)/test") }
    }
  }
}

def checkstyleConfigProperties(configFileName) {
  [importControlFile: "$configFileName"]
}

if (userEnableTestCoverage) {
  tasks.register('reportCoverage').configure { dependsOn(subprojects.reportCoverage) }
}

def connectPkgs = [
        'connect:api',
        'connect:basic-auth-extension',
        'connect:file',
        'connect:json',
        'connect:runtime',
        'connect:test-plugins',
        'connect:transforms',
        'connect:mirror',
        'connect:mirror-client'
]

tasks.create(name: "jarConnect", dependsOn: connectPkgs.collect { it + ":jar" }) {}

tasks.create(name: "testConnect", dependsOn: connectPkgs.collect { it + ":test" }) {}

project(':generator') {
  dependencies {
    implementation libs.argparse4j
    implementation libs.jacksonDatabind
    implementation libs.jacksonJDK8Datatypes
    implementation libs.jacksonJakartarsJsonProvider

    implementation 'org.eclipse.jgit:org.eclipse.jgit:6.4.0.202211300538-r'
    // SSH support for JGit based on Apache MINA sshd
    implementation 'org.eclipse.jgit:org.eclipse.jgit.ssh.apache:6.4.0.202211300538-r'
    // GPG support for JGit based on BouncyCastle (commit signing)
    implementation 'org.eclipse.jgit:org.eclipse.jgit.gpg.bc:6.4.0.202211300538-r'

    testImplementation libs.junitJupiter

    testRuntimeOnly runtimeTestLibs
  }

  javadoc {
    enabled = false
  }
}

project(':clients') {
  base {
    archivesName = "kafka-clients"
  }

  configurations {
    generator
    shadowed
  }

  dependencies {
    implementation libs.zstd
    implementation libs.lz4
    implementation libs.snappy
    implementation libs.opentelemetryProto
    implementation libs.protobuf
    implementation libs.slf4jApi

    // libraries which should be added as runtime dependencies in generated pom.xml should be defined here:
    shadowed libs.zstd
    shadowed libs.lz4
    shadowed libs.snappy
    shadowed libs.slf4jApi

    compileOnly libs.jacksonDatabind // for SASL/OAUTHBEARER bearer token parsing
    compileOnly libs.jacksonJDK8Datatypes
    compileOnly libs.jose4j          // for SASL/OAUTHBEARER JWT validation; only used by broker

    testImplementation libs.bcpkix
    testImplementation libs.jacksonJakartarsJsonProvider
    testImplementation libs.jose4j
    testImplementation libs.junitJupiter
    testImplementation libs.spotbugs
    testImplementation libs.mockitoCore
    testImplementation libs.mockitoJunitJupiter // supports MockitoExtension
    testImplementation testLog4j2Libs

    testCompileOnly libs.bndlib

    testRuntimeOnly libs.jacksonDatabind
    testRuntimeOnly libs.jacksonJDK8Datatypes
    testRuntimeOnly runtimeTestLibs

    generator project(':generator')
  }

  task createVersionFile() {
    def receiptFile = file("$buildDir/kafka/$buildVersionFileName")
    inputs.property "commitId", commitId
    inputs.property "version", version
    outputs.file receiptFile
    outputs.cacheIf { true }

    doLast {
      def data = [
              commitId: commitId,
              version: version,
      ]

      receiptFile.parentFile.mkdirs()
      def content = data.entrySet().collect { "$it.key=$it.value" }.sort().join("\n")
      receiptFile.setText(content, "ISO-8859-1")
    }
  }

  shadowJar {
    dependsOn createVersionFile
    // archiveClassifier defines the classifier for the shadow jar, the default is 'all'.
    // We don't want to use the default classifier because it will cause the shadow jar to
    // overwrite the original jar. We also don't want to use the 'shadow' classifier because
    // it will cause the shadow jar to be named kafka-clients-shadow.jar. We want to use the
    // same name as the original jar, kafka-clients.jar.
    archiveClassifier = null
    // KIP-714: move shaded dependencies to a shaded location
    relocate('io.opentelemetry.proto', 'org.apache.kafka.shaded.io.opentelemetry.proto')
    relocate('com.google.protobuf', 'org.apache.kafka.shaded.com.google.protobuf')

    // dependencies excluded from the final jar, since they are declared as runtime dependencies
    dependencies {
      project.configurations.shadowed.allDependencies.each {
        exclude(dependency(it.group + ':' + it.name))
      }
      // exclude proto files from the jar
      exclude "**/opentelemetry/proto/**/*.proto"
      exclude "**/google/protobuf/*.proto"
    }

    from("$buildDir") {
      include "kafka/$buildVersionFileName"
    }

    from "$rootDir/LICENSE"
    from "$rootDir/NOTICE"
  }

  jar {
    enabled false
    dependsOn 'shadowJar'
  }

  clean.doFirst {
    delete "$buildDir/kafka/"
  }

  task processMessages(type:JavaExec) {
    mainClass = "org.apache.kafka.message.MessageGenerator"
    classpath = configurations.generator
    args = [ "-p", "org.apache.kafka.common.message",
             "-o", "${projectDir}/build/generated/main/java/org/apache/kafka/common/message",
             "-i", "src/main/resources/common/message",
             "-t", "ApiMessageTypeGenerator",
             "-m", "MessageDataGenerator", "JsonConverterGenerator"
    ]
    inputs.dir("src/main/resources/common/message")
            .withPropertyName("messages")
            .withPathSensitivity(PathSensitivity.RELATIVE)
    outputs.cacheIf { true }
    outputs.dir("${projectDir}/build/generated/main/java/org/apache/kafka/common/message")
  }

  task processMessagesRust(type:JavaExec) {
    mainClass = "org.apache.kafka.message.RustMessageGenerator"
    classpath = configurations.generator
    args = [ "-o", "../rust/src",
             "-i", "src/main/resources/common/message"
    ]
    inputs.dir("src/main/resources/common/message")
            .withPropertyName("messages")
            .withPathSensitivity(PathSensitivity.RELATIVE)
    outputs.cacheIf { true }
    outputs.dir("../rust/src")
  }

  task processTestMessages(type:JavaExec) {
    mainClass = "org.apache.kafka.message.MessageGenerator"
    classpath = configurations.generator
    args = [ "-p", "org.apache.kafka.common.message",
             "-o", "${projectDir}/build/generated/test/java/org/apache/kafka/common/message",
             "-i", "src/test/resources/common/message",
             "-m", "MessageDataGenerator", "JsonConverterGenerator"
    ]
    inputs.dir("src/test/resources/common/message")
            .withPropertyName("testMessages")
            .withPathSensitivity(PathSensitivity.RELATIVE)
    outputs.cacheIf { true }
    outputs.dir("${projectDir}/build/generated/test/java/org/apache/kafka/common/message")
  }

  sourceSets {
    main {
      java {
        srcDirs = ["src/main/java", "${projectDir}/build/generated/main/java"]
      }
    }
    test {
      java {
        srcDirs = ["src/test/java", "${projectDir}/build/generated/test/java"]
      }
    }
  }

  compileJava.dependsOn 'processMessages'
  srcJar.dependsOn 'processMessages'

  compileTestJava.dependsOn 'processTestMessages'

  javadoc {
    include "**/org/apache/kafka/clients/admin/*"
    include "**/org/apache/kafka/clients/consumer/*"
    include "**/org/apache/kafka/clients/producer/*"
    include "**/org/apache/kafka/common/*"
    include "**/org/apache/kafka/common/acl/*"
    include "**/org/apache/kafka/common/annotation/*"
    include "**/org/apache/kafka/common/errors/*"
    include "**/org/apache/kafka/common/header/*"
    include "**/org/apache/kafka/common/metrics/*"
    include "**/org/apache/kafka/common/metrics/stats/*"
    include "**/org/apache/kafka/common/quota/*"
    include "**/org/apache/kafka/common/resource/*"
    include "**/org/apache/kafka/common/serialization/*"
    include "**/org/apache/kafka/common/config/*"
    include "**/org/apache/kafka/common/config/provider/*"
    include "**/org/apache/kafka/common/security/auth/*"
    include "**/org/apache/kafka/common/security/plain/*"
    include "**/org/apache/kafka/common/security/scram/*"
    include "**/org/apache/kafka/common/security/token/delegation/*"
    include "**/org/apache/kafka/common/security/oauthbearer/*"
    include "**/org/apache/kafka/common/security/oauthbearer/secured/*"
    include "**/org/apache/kafka/server/authorizer/*"
    include "**/org/apache/kafka/server/policy/*"
    include "**/org/apache/kafka/server/quota/*"
    include "**/org/apache/kafka/server/telemetry/*"
  }
}

project(':java-tester') {
  apply plugin: 'application'

  checkstyle {
    ignoreFailures = true
    showViolations = false
  }

  spotbugs {
    ignoreFailures = true
  }

  dependencies {
    implementation project(':clients')
    implementation libs.jacksonDatabind
    implementation libs.commonsText
  }

  application {
    mainClass = 'me.ivanyu.java_tester.JavaTester'
  }
}

task aggregatedJavadoc(type: Javadoc, dependsOn: compileJava) {
  def projectsWithJavadoc = subprojects.findAll { it.javadoc.enabled }
  source = projectsWithJavadoc.collect { it.sourceSets.main.allJava }
  classpath = files(projectsWithJavadoc.collect { it.sourceSets.main.compileClasspath })
  includes = projectsWithJavadoc.collectMany { it.javadoc.getIncludes() }
  excludes = projectsWithJavadoc.collectMany { it.javadoc.getExcludes() }
}
